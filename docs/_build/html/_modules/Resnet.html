<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Resnet &#8212; AlphaZeroChomp 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=61cd365c" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=12dfc556" />
    <script src="../_static/documentation_options.js?v=8d563738"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for Resnet</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>

<div class="viewcode-block" id="ResNet">
<a class="viewcode-back" href="../modules.html#Resnet.ResNet">[docs]</a>
<span class="k">class</span> <span class="nc">ResNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;seed&#39;</span><span class="p">]</span>
        <span class="n">num_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;num_hidden&#39;</span><span class="p">]</span>
        <span class="n">num_resBlocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;num_resBlocks&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;max_size&#39;</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">startBlock</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">backBone</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">ResBlock</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_resBlocks</span><span class="p">)]</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">policyHead</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">valueHead</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_size</span> <span class="p">,</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># Adjust the input size here</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_seed</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_device</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_weights</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coordinates_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_coordinate_matrix</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>   <span class="c1">#Adds coordinates to exploit simmetries</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;verbose_resnet&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ResNet Device: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ResNet:</span><span class="se">\n</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="ResNet.set_device">
<a class="viewcode-back" href="../modules.html#Resnet.ResNet.set_device">[docs]</a>
    <span class="k">def</span> <span class="nf">set_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the device for the PyTorch model based on the specified model device and availability.</span>

<span class="sd">        This function updates the model to use &#39;mps&#39; if specified and available, otherwise &#39;cuda&#39;</span>
<span class="sd">        if specified and available, and defaults to &#39;cpu&#39; if neither is available.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        None</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;model_device&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;mps&#39;</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;mps&#39;</span><span class="p">)</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;mps&#39;</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;model_device&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span></div>


<div class="viewcode-block" id="ResNet.create_coordinate_matrix">
<a class="viewcode-back" href="../modules.html#Resnet.ResNet.create_coordinate_matrix">[docs]</a>
    <span class="k">def</span> <span class="nf">create_coordinate_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a symmetric matrix with unique diagonal elements and symmetric off-diagonal elements.</span>

<span class="sd">        The matrix is of size `(max_size, max_size)` with diagonal elements from `0` to `max_size - 1`</span>
<span class="sd">        and symmetric off-diagonal elements that encode positional symmetries.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            A symmetric matrix with unique diagonal elements and symmetric off-diagonal elements.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">max_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;max_size&#39;</span><span class="p">]</span>
        <span class="n">matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_size</span><span class="p">,</span> <span class="n">max_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_size</span><span class="p">):</span>
            <span class="n">matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

        <span class="n">positive_value</span> <span class="o">=</span> <span class="n">max_size</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_size</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">max_size</span><span class="p">):</span>
                <span class="n">matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_value</span>
                <span class="n">matrix</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_value</span>
                <span class="n">positive_value</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">matrix</span></div>


<div class="viewcode-block" id="ResNet.set_seed">
<a class="viewcode-back" href="../modules.html#Resnet.ResNet.set_seed">[docs]</a>
    <span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;Set all possible seeds to make the experiment reproducibol&#39;&#39;&#39;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># if you are using multi-GPU but im not now</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span></div>


    <span class="k">def</span> <span class="nf">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;Set the weights and biases to make the experiment reproducibol&#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<div class="viewcode-block" id="ResNet.mask_and_renormalize">
<a class="viewcode-back" href="../modules.html#Resnet.ResNet.mask_and_renormalize">[docs]</a>
    <span class="k">def</span> <span class="nf">mask_and_renormalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_input</span><span class="p">,</span> <span class="n">unrenorm_policy</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Masks and renormalizes the policy using the Softmax function.</span>

<span class="sd">        This method applies a mask to the policy to exclude invalid moves, then renormalizes</span>
<span class="sd">        the policy using the Softmax function. It can handle both batched and unbatched inputs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_input : torch.Tensor</span>
<span class="sd">            Input tensor representing the state, either batched (3D) or unbatched (2D).</span>
<span class="sd">        unrenorm_policy : torch.Tensor</span>
<span class="sd">            Unrenormalized policy tensor to be masked and renormalized.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Masked and renormalized policy tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">x_input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Unbatched input</span>
            <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">unrenorm_policy</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">x_input_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x_input</span><span class="p">)</span>
            <span class="n">masked_policy</span><span class="p">[</span><span class="n">x_input_flat</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
            <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">masked_policy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">x_input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># Batched input</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_input</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">unrenorm_policy</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">x_input_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x_input</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                <span class="n">masked_policy</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">x_input_flat</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
            <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">masked_policy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#The dim=1 because dim=0 is batch_dim</span>

        <span class="k">return</span> <span class="n">masked_policy</span></div>



<div class="viewcode-block" id="ResNet.mask_and_renorm_NoSoftmax">
<a class="viewcode-back" href="../modules.html#Resnet.ResNet.mask_and_renorm_NoSoftmax">[docs]</a>
    <span class="k">def</span> <span class="nf">mask_and_renorm_NoSoftmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_input</span><span class="p">,</span> <span class="n">unrenorm_policy</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Masks and renormalizes the policy without using the Softmax function.</span>

<span class="sd">        This method applies a mask to the policy to exclude invalid moves and renormalizes</span>
<span class="sd">        the policy without using the Softmax function. It works best with args[&#39;MCTS_set_equal_prior&#39;] = True</span>
<span class="sd">        and allows faster convergence of the ResNet network. This function can handle both batched and unbatched inputs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_input : torch.Tensor</span>
<span class="sd">            Input tensor representing the state, either batched (3D) or unbatched (2D).</span>
<span class="sd">        unrenorm_policy : torch.Tensor</span>
<span class="sd">            Unrenormalized policy tensor to be masked and renormalized.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Masked and renormalized policy tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">x_input</span> <span class="o">=</span> <span class="n">x_input</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">x_input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Unbatched input</span>
            <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">unrenorm_policy</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">x_input_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x_input</span><span class="p">)</span>
            <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">masked_policy</span> <span class="o">*</span> <span class="n">x_input_flat</span>  <span class="c1">#  element-wise multiplication</span>
            <span class="n">sum_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">masked_policy</span><span class="p">)</span>
            <span class="c1">#print(f&quot;Unbatched sum_probs: {sum_probs}&quot;)</span>
            <span class="k">if</span> <span class="n">sum_probs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">masked_policy</span> <span class="o">/</span> <span class="n">sum_probs</span>
                <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">masked_policy</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">masked_policy</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">x_input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># Batched input</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_input</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">masked_policy</span> <span class="o">=</span> <span class="n">unrenorm_policy</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">x_input_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x_input</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">masked_policy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">masked_policy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_input_flat</span>
                <span class="n">sum_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">masked_policy</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                <span class="k">if</span> <span class="n">sum_probs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">masked_policy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">masked_policy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">sum_probs</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">masked_policy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">masked_policy</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">masked_policy</span></div>



<div class="viewcode-block" id="ResNet.prepare_data">
<a class="viewcode-back" href="../modules.html#Resnet.ResNet.prepare_data">[docs]</a>
    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_input</span><span class="p">,</span> <span class="n">current_actions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">opponent_actions</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepares input data for a neural network model by incorporating current and opponent actions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_input : torch.Tensor</span>
<span class="sd">            The state of the game.</span>
<span class="sd">        current_actions : list or torch.Tensor, optional</span>
<span class="sd">            Actions taken by the current player. For self-play, it is a list of tuples with coordinates of actions.</span>
<span class="sd">            For training, it is a matrix of dimensions (max_size, max_size) with +1 at action coordinates.</span>
<span class="sd">        opponent_actions : list or torch.Tensor, optional</span>
<span class="sd">            Actions taken by the opponent player. For self-play, it is a list of tuples with coordinates of actions.</span>
<span class="sd">            For training, it is a matrix of dimensions (max_size, max_size) with -1 at action coordinates.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The modified input data after processing, which includes the current player&#39;s actions, opponent&#39;s actions,</span>
<span class="sd">            the original input state, and a coordinates matrix stacked together.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">x_input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Unbatched input</span>
            <span class="n">current</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;max_size&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;max_size&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">opponent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;max_size&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;max_size&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">current_actions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">opponent_actions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">current_actions</span><span class="p">:</span>
                    <span class="n">current</span><span class="p">[</span><span class="n">action</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>
                <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">opponent_actions</span><span class="p">:</span>
                    <span class="n">opponent</span><span class="p">[</span><span class="n">action</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
            <span class="n">x_input_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">current</span><span class="p">,</span> <span class="n">x_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">opponent</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coordinates_matrix</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">x_input_mod</span> <span class="o">=</span> <span class="n">x_input_mod</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add batch dimension</span>

        <span class="k">elif</span> <span class="n">x_input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># Batched input</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_input</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>    <span class="c1">#dynamic batching</span>
            <span class="n">x_input_mod</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">current</span> <span class="o">=</span> <span class="n">current_actions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">opponent</span> <span class="o">=</span> <span class="n">opponent_actions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">x_input_m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">current</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">x_input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">opponent</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">coordinates_matrix</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">x_input_mod</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_input_m</span><span class="p">)</span>
            <span class="n">x_input_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_input_mod</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Stack along the batch dimension</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The input shape: </span><span class="si">{</span><span class="n">x_input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2"> do not correspond to the possibilities!&quot;</span><span class="p">)</span>

        <span class="n">x_input_mod</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x_input_mod</span></div>



<div class="viewcode-block" id="ResNet.forward">
<a class="viewcode-back" href="../modules.html#Resnet.ResNet.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_input</span><span class="p">,</span> <span class="n">current_actions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">opponent_actions</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">x_prep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">(</span><span class="n">x_input</span><span class="p">,</span> <span class="n">current_actions</span><span class="p">,</span> <span class="n">opponent_actions</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">startBlock</span><span class="p">(</span><span class="n">x_prep</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">resBlock</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">backBone</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">resBlock</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policyHead</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valueHead</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">masked_policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_and_renorm_NoSoftmax</span><span class="p">(</span><span class="n">x_input</span><span class="p">,</span> <span class="n">policy</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;MCTS_set_equal_prior&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_and_renormalize</span><span class="p">(</span><span class="n">x_input</span><span class="p">,</span> <span class="n">policy</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">masked_policy</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">value</span></div>
</div>



<div class="viewcode-block" id="ResBlock">
<a class="viewcode-back" href="../modules.html#Resnet.ResBlock">[docs]</a>
<span class="k">class</span> <span class="nc">ResBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A Residual Block for a neural network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_hidden : int</span>
<span class="sd">        Number of hidden units in the convolutional layers.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    forward(x)</span>
<span class="sd">        Performs the forward pass of the residual block.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">)</span>

<div class="viewcode-block" id="ResBlock.forward">
<a class="viewcode-back" href="../modules.html#Resnet.ResBlock.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        .. :no-index:</span>
<span class="sd">        The `forward` function defines the forward pass of the ResNet block.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">+=</span> <span class="n">residual</span>   <span class="c1"># Residual addingtion</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>
</div>



<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">args = {</span>
<span class="sd">    &#39;min_size&#39;: 2,</span>
<span class="sd">    &#39;max_size&#39;: 6,</span>
<span class="sd">    &#39;save_data_env&#39;: False,</span>
<span class="sd">    &#39;model_device&#39;: &#39;cpu&#39;,</span>
<span class="sd">    &#39;verbose_game&#39;: False,</span>
<span class="sd">    &#39;verbose_mcts&#39;: True,</span>
<span class="sd">    &#39;verbose_resnet&#39;: True,</span>
<span class="sd">    &#39;mix_up&#39;: False,</span>
<span class="sd">    &#39;C&#39;: 1.4,</span>
<span class="sd">    &#39;num_searches&#39;: 300,</span>
<span class="sd">    &#39;num_hidden&#39; : 64,</span>
<span class="sd">    &#39;num_resBlocks&#39;: 16,</span>
<span class="sd">    &#39;seed&#39; : 42,</span>
<span class="sd">    &#39;only_path_backpropagation&#39; : True,</span>
<span class="sd">    &#39;MCTS_set_equal_prior&#39;:True    #Set equal prior for all child node when expanded</span>
<span class="sd">}</span>
<span class="sd">resnt = ResNet(args)</span>
<span class="sd">print(f&quot;{resnt.coordinates_matrix}&quot;)&#39;&#39;&#39;</span>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">AlphaZeroChomp</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">AlphaZeroChomp</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Alessandro Canzonieri.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>